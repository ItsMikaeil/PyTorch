{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "given-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/home/mikaeil/Desktop/Dataset/Taxi Dataset/NYCTaxiFares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handy-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "universal-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blind-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-tracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vital-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      " 8   dist_km            120000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coral-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime']= pd.to_datetime(df['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lovely-party",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   pickup_datetime    120000 non-null  datetime64[ns, UTC]\n",
      " 1   fare_amount        120000 non-null  float64            \n",
      " 2   fare_class         120000 non-null  int64              \n",
      " 3   pickup_longitude   120000 non-null  float64            \n",
      " 4   pickup_latitude    120000 non-null  float64            \n",
      " 5   dropoff_longitude  120000 non-null  float64            \n",
      " 6   dropoff_latitude   120000 non-null  float64            \n",
      " 7   passenger_count    120000 non-null  int64              \n",
      " 8   dist_km            120000 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "disciplinary-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['EDTdate']= df['pickup_datetime']- pd.Timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "injured-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour']= df['EDTdate'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "actual-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMorPM']= np.where(df['Hour']<12, 'am', 'pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "breeding-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekday']= df['EDTdate'].dt.strftime('%a')#  dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informational-earthquake",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km                   EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56+00:00     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53+00:00    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26+00:00     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03+00:00    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01+00:00    22     pm     Fri  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equivalent-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols= ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols= ['pickup_longitude',\n",
    "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "       'passenger_count', 'dist_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "burning-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_col= ['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "numeric-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    df[cat]= df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opposite-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      datetime64[ns, UTC]\n",
       "fare_amount                      float64\n",
       "fare_class                         int64\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude                float64\n",
       "dropoff_latitude                 float64\n",
       "passenger_count                    int64\n",
       "dist_km                          float64\n",
       "EDTdate              datetime64[ns, UTC]\n",
       "Hour                            category\n",
       "AMorPM                          category\n",
       "Weekday                         category\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "verbal-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "capable-handbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    am\n",
       "1    am\n",
       "2    am\n",
       "3    pm\n",
       "4    pm\n",
       "Name: AMorPM, dtype: category\n",
       "Categories (2, object): ['am', 'pm']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "typical-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Mon\n",
       "1    Sat\n",
       "2    Sat\n",
       "3    Sun\n",
       "4    Fri\n",
       "Name: Weekday, dtype: category\n",
       "Categories (7, object): ['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "supported-andrew",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "119995    0\n",
       "119996    0\n",
       "119997    1\n",
       "119998    0\n",
       "119999    1\n",
       "Length: 120000, dtype: int8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "serious-compatibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "offensive-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr= df['Hour'].cat.codes.values\n",
    "ampm= df['AMorPM'].cat.codes.values\n",
    "wkdy= df['Weekday'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opposed-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11,  7, ..., 14,  4, 12], dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "committed-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= np.stack([hr, ampm, wkdy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "optimum-segment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       ...,\n",
       "       [14,  1,  3],\n",
       "       [ 4,  0,  5],\n",
       "       [12,  1,  2]], dtype=int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "controlled-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cats=np.stack([df[col].cat.codes.values for col in cat_cols],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baking-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= torch.tensor(cats, dtype= torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "circular-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts=np.stack([df[col].values for col in cont_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "elect-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts= torch.tensor(conts, dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cleared-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor(df[y_col].values,dtype= torch.float).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "photographic-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate category size\n",
    "cat_szs= [len(df[col].cat.categories) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "closed-poison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 2, 7]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sufficient-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate embedding size\n",
    "emb_szs= [(size, min(50, (size+1)//2))for size in cat_szs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "nominated-trade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "returning-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "catz=cats[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "naughty-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aggressive-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of embedding layers\n",
    "selfembeds= nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in emb_szs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "featured-zoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intellectual-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingz= []\n",
    "\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "authentic-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.4325, -0.3552, -0.3853, -0.5851, -0.7315, -2.4092,  0.9159,  0.3791,\n",
       "          -0.1599,  1.5418, -0.8957, -2.4161],\n",
       "         [ 0.1542,  0.2536,  0.4741, -0.4527,  0.6275,  1.7840,  0.0418,  2.4309,\n",
       "          -0.9698, -1.3570,  0.8834,  0.3976]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[0.9250],\n",
       "         [0.9250]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[-1.8671, -0.2842, -0.5907, -0.7124],\n",
       "         [ 1.1225,  0.3230,  1.5499,  1.4941]], grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "standing-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "z= torch.cat(embeddingz, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "english-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4325, -0.3552, -0.3853, -0.5851, -0.7315, -2.4092,  0.9159,  0.3791,\n",
       "         -0.1599,  1.5418, -0.8957, -2.4161,  0.9250, -1.8671, -0.2842, -0.5907,\n",
       "         -0.7124],\n",
       "        [ 0.1542,  0.2536,  0.4741, -0.4527,  0.6275,  1.7840,  0.0418,  2.4309,\n",
       "         -0.9698, -1.3570,  0.8834,  0.3976,  0.9250,  1.1225,  0.3230,  1.5499,\n",
       "          1.4941]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caring-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfembdrop= nn.Dropout(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acceptable-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "z= selfembdrop(z) # pass to droupout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "deluxe-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.5920, -0.6421, -0.0000, -0.0000, -0.0000,  0.0000,  0.6318,\n",
       "         -0.2664,  2.5697, -1.4928, -0.0000,  0.0000, -0.0000, -0.0000, -0.9845,\n",
       "         -1.1874],\n",
       "        [ 0.2569,  0.4226,  0.7902, -0.7545,  1.0458,  2.9734,  0.0697,  4.0514,\n",
       "         -1.6163, -0.0000,  1.4723,  0.6626,  1.5417,  0.0000,  0.0000,  2.5832,\n",
       "          0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "distant-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeds= nn.ModuleList([nn.Embedding(ni,nf) for ni, nf in emb_szs])\n",
    "        self.emb_drop= nn.Dropout(p)\n",
    "        self.bn_cont= nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist=[]\n",
    "        n_emb= sum(nf for ni,nf in emb_szs )\n",
    "        n_in = n_emb + n_cont  # sum of all input features\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.ReLU(inplace= True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in=i\n",
    "            \n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        \n",
    "        self.layers= nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings= []\n",
    "        \n",
    "        \n",
    "        for i, e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "            \n",
    "        x= torch.cat(embeddings, 1)\n",
    "        x= self.emb_drop(x)\n",
    "            \n",
    "        x_cont= self.bn_cont(x_cont) # pass through nomalization layer\n",
    "        x=torch.cat([x, x_cont], 1)  # adding up categorical and continous data \n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "black-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "\n",
    "model= TabularModel(emb_szs, conts.shape[1], 1,[200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cloudy-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "geological-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.MSELoss()\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr= 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "sublime-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 120000\n",
    "test_size= int(batch_size*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "overall-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train= cats[:batch_size - test_size]\n",
    "cat_test= cats[batch_size - test_size: batch_size]\n",
    "con_train= conts[:batch_size - test_size]\n",
    "con_test= conts[batch_size - test_size : batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "differential-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y[:batch_size - test_size]\n",
    "y_test= y[batch_size - test_size: batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "protective-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaeil/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([96000, 1])) that is different to the input size (torch.Size([96000, 23])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss is 12.626952171325684\n",
      "epoch: 11 loss is 12.128745079040527\n",
      "epoch: 21 loss is 11.66796588897705\n",
      "epoch: 31 loss is 11.248017311096191\n",
      "epoch: 41 loss is 10.874324798583984\n",
      "epoch: 51 loss is 10.54636287689209\n",
      "epoch: 61 loss is 10.26839542388916\n",
      "epoch: 71 loss is 10.027616500854492\n",
      "epoch: 81 loss is 9.833477020263672\n",
      "epoch: 91 loss is 9.678089141845703\n",
      "epoch: 101 loss is 9.545310020446777\n",
      "epoch: 111 loss is 9.45255184173584\n",
      "epoch: 121 loss is 9.3724365234375\n",
      "epoch: 131 loss is 9.30604362487793\n",
      "epoch: 141 loss is 9.259363174438477\n",
      "epoch: 151 loss is 9.223464012145996\n",
      "epoch: 161 loss is 9.198450088500977\n",
      "epoch: 171 loss is 9.178739547729492\n",
      "epoch: 181 loss is 9.16048812866211\n",
      "epoch: 191 loss is 9.146690368652344\n",
      "epoch: 201 loss is 9.137798309326172\n",
      "epoch: 211 loss is 9.131519317626953\n",
      "epoch: 221 loss is 9.12613582611084\n",
      "epoch: 231 loss is 9.119963645935059\n",
      "epoch: 241 loss is 9.120931625366211\n",
      "epoch: 251 loss is 9.116294860839844\n",
      "epoch: 261 loss is 9.118053436279297\n",
      "epoch: 271 loss is 9.121623992919922\n",
      "epoch: 281 loss is 9.121337890625\n",
      "epoch: 291 loss is 9.11902904510498\n",
      "epoch: 301 loss is 9.113494873046875\n",
      "epoch: 311 loss is 9.118026733398438\n",
      "epoch: 321 loss is 9.116890907287598\n",
      "epoch: 331 loss is 9.111648559570312\n",
      "epoch: 341 loss is 9.11191177368164\n",
      "epoch: 351 loss is 9.115616798400879\n",
      "epoch: 361 loss is 9.111795425415039\n",
      "epoch: 371 loss is 9.114527702331543\n",
      "epoch: 381 loss is 9.11279296875\n",
      "epoch: 391 loss is 9.114333152770996\n",
      "epoch: 401 loss is 9.121636390686035\n",
      "epoch: 411 loss is 9.112340927124023\n",
      "epoch: 421 loss is 9.111888885498047\n",
      "epoch: 431 loss is 9.113512992858887\n",
      "epoch: 441 loss is 9.11393928527832\n",
      "epoch: 451 loss is 9.111920356750488\n",
      "epoch: 461 loss is 9.111438751220703\n",
      "epoch: 471 loss is 9.117979049682617\n",
      "epoch: 481 loss is 9.114466667175293\n",
      "epoch: 491 loss is 9.116436958312988\n",
      "Training took 2.5333877205848694 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "epochs= 500\n",
    "losses= []\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "    y_pred= model(cat_train, con_train)\n",
    "    loss= torch.sqrt(criterion(y_pred, y_train))\n",
    "    losses.append(loss)\n",
    "    \n",
    "    \n",
    "    if i%10==1:\n",
    "        print(f'epoch: {i} loss is {loss}')\n",
    "        \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "duration= time.time() - start_time\n",
    "print(f'Training took {duration/60} minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "clean-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaeil/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([24000, 1])) that is different to the input size (torch.Size([24000, 23])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    " with torch.no_grad():\n",
    "        y_val= model(cat_test, con_test)\n",
    "        loss= torch.sqrt(criterion(y_val, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "artistic-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1082)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
